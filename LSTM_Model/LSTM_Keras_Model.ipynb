{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f = open(\"3000_data/new.group1.pkl\", 'r')\n",
    "group1 = pickle.load(f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "f = open(\"3000_data/new.group2.pkl\", 'r')\n",
    "group2 = pickle.load(f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f = open(\"3000_data/new.group3.pkl\", 'r')\n",
    "group3 = pickle.load(f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f = open(\"3000_data/new.group4.pkl\", 'r')\n",
    "group4 = pickle.load(f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f = open(\"3000_data/new.group5.pkl\", 'r')\n",
    "group5 = pickle.load(f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f = open(\"3000_data/new.group6.pkl\", 'r')\n",
    "group6 = pickle.load(f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f = open(\"3000_data/new.group7.pkl\", 'r')\n",
    "group7 = pickle.load(f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f = open(\"3000_data/new.group8.pkl\", 'r')\n",
    "group8 = pickle.load(f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f = open(\"3000_data/new.group9.pkl\", 'r')\n",
    "group9 = pickle.load(f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f = open(\"3000_data/new.group10.pkl\", 'r')\n",
    "group10 = pickle.load(f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Shape of data (batch_size, drug_seq, 9318)\n",
    "import random\n",
    "\n",
    "numFeatures = 9318\n",
    "numOutput = 100\n",
    "\n",
    "def chooseGroup(number):\n",
    "    if number == 1:\n",
    "        return group1\n",
    "    elif number == 2:\n",
    "        return group2\n",
    "    elif number == 3:\n",
    "        return group3\n",
    "    elif number == 4:\n",
    "        return group4\n",
    "    elif number == 5:\n",
    "        return group5\n",
    "    elif number == 6:\n",
    "        return group6\n",
    "    elif number == 7:\n",
    "        return group7\n",
    "    elif number == 8:\n",
    "        return group8\n",
    "    elif number == 9:\n",
    "        return group9\n",
    "    elif number == 10:\n",
    "        return group10\n",
    "\n",
    "def generator(batch_size):\n",
    "    \n",
    "    while True: #Infinite Loop\n",
    "    \n",
    "        #Randomly select a group\n",
    "        groupNumber = random.randint(1,9)\n",
    "\n",
    "        #Extract group\n",
    "        group = chooseGroup(groupNumber)\n",
    "\n",
    "        # Create empty arrays to contain batch of features and labels\n",
    "        batch_features = np.empty((batch_size, groupNumber, numFeatures))\n",
    "        batch_labels = np.empty((batch_size, groupNumber, numOutput))\n",
    "        \n",
    "        for i in range(batch_size):\n",
    "            # choose random index in features\n",
    "            index= random.randint(0,len(group)-1)\n",
    "            \n",
    "            #np.nan_to_num transforms nan to 0. Without removing nan, the loss function is nan\n",
    "            #The second index is to guarantee that we have only groupNumber samples (remove duplicate)\n",
    "            batch_features[i] = np.nan_to_num(group[index][0:groupNumber])\n",
    "            #batch_features[i] = np.nan_to_num(group[index])\n",
    "            \n",
    "            #Randomly generated output\n",
    "            batch_labels[i] = np.random.randint(2, size=(groupNumber,numOutput)) \n",
    "            \n",
    "        yield batch_features, batch_labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Define Data Parameters\n",
    "batch_size = 100\n",
    "output_size = numOutput\n",
    "number_features = numFeatures\n",
    "\n",
    "#Model Parameters\n",
    "epochs = 20\n",
    "steps_per_epochs = 1\n",
    "loss_function = \"categorical_crossentropy\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      " - 3s - loss: 433.6866\n",
      "Epoch 2/20\n",
      " - 1s - loss: 411.1126\n",
      "Epoch 3/20\n",
      " - 1s - loss: 332.3379\n",
      "Epoch 4/20\n",
      " - 1s - loss: 275.9017\n",
      "Epoch 5/20\n",
      " - 0s - loss: 267.4915\n",
      "Epoch 6/20\n",
      " - 1s - loss: 262.1610\n",
      "Epoch 7/20\n",
      " - 0s - loss: 264.4459\n",
      "Epoch 8/20\n",
      " - 0s - loss: 258.9502\n",
      "Epoch 9/20\n",
      " - 0s - loss: 261.4356\n",
      "Epoch 10/20\n",
      " - 1s - loss: 261.4955\n",
      "Epoch 11/20\n",
      " - 0s - loss: 259.1483\n",
      "Epoch 12/20\n",
      " - 0s - loss: 259.3895\n",
      "Epoch 13/20\n",
      " - 1s - loss: 258.3217\n",
      "Epoch 14/20\n",
      " - 0s - loss: 257.4506\n",
      "Epoch 15/20\n",
      " - 1s - loss: 257.3934\n",
      "Epoch 16/20\n",
      " - 1s - loss: 258.3708\n",
      "Epoch 17/20\n",
      " - 0s - loss: 256.5113\n",
      "Epoch 18/20\n",
      " - 0s - loss: 252.2733\n",
      "Epoch 19/20\n",
      " - 0s - loss: 254.8192\n",
      "Epoch 20/20\n",
      " - 0s - loss: 254.7219\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x13e1c6f50>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(output_size, input_shape= (None,number_features), return_sequences=True, activation='softmax', recurrent_activation='softmax'))\n",
    "model.add(Dense(output_size))\n",
    "model.compile(loss=loss_function, optimizer='adam')\n",
    "#model.fit(x, y, epochs=epochs, batch_size=batch_size, verbose=2)\n",
    "model.fit_generator(generator=generator(batch_size), steps_per_epoch=steps_per_epochs, epochs=epochs, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_4 (LSTM)                (None, None, 100)         3767600   \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, None, 100)         10100     \n",
      "=================================================================\n",
      "Total params: 3,777,700\n",
      "Trainable params: 3,777,700\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
