{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.metrics import categorical_accuracy, binary_accuracy\n",
    "\n",
    "import pickle\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Read X\n",
    "\n",
    "# f = open(\"pickle_files/group1_x_sparse.pkl\", 'r')\n",
    "# group1_x = pickle.load(f)\n",
    "# f.close()\n",
    "\n",
    "# f = open(\"pickle_files/group2_x_sparse.pkl\", 'r')\n",
    "# group2_x = pickle.load(f)\n",
    "# f.close()\n",
    "\n",
    "f = open(\"pickle_files/group3_x_sparse.pkl\", 'r')\n",
    "group3_x = pickle.load(f)\n",
    "f.close()\n",
    "\n",
    "f = open(\"pickle_files/group4_x_sparse.pkl\", 'r')\n",
    "group4_x = pickle.load(f)\n",
    "f.close()\n",
    "\n",
    "f = open(\"pickle_files/group5_x_sparse.pkl\", 'r')\n",
    "group5_x = pickle.load(f)\n",
    "f.close()\n",
    "\n",
    "f = open(\"pickle_files/group6_x_sparse.pkl\", 'r')\n",
    "group6_x = pickle.load(f)\n",
    "f.close()\n",
    "\n",
    "f = open(\"pickle_files/group7_x_sparse.pkl\", 'r')\n",
    "group7_x = pickle.load(f)\n",
    "f.close()\n",
    "\n",
    "f = open(\"pickle_files/group8_x_sparse.pkl\", 'r')\n",
    "group8_x = pickle.load(f)\n",
    "f.close()\n",
    "\n",
    "f = open(\"pickle_files/group9_x_sparse.pkl\", 'r')\n",
    "group9_x = pickle.load(f)\n",
    "f.close()\n",
    "\n",
    "f = open(\"pickle_files/group10_x_sparse.pkl\", 'r')\n",
    "group10_x = pickle.load(f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Read Y\n",
    "\n",
    "# f = open(\"pickle_files/group1_y_sparse.pkl\", 'r')\n",
    "# group1_y = pickle.load(f)\n",
    "# f.close()\n",
    "\n",
    "# f = open(\"pickle_files/group2_y_sparse.pkl\", 'r')\n",
    "# group2_y = pickle.load(f)\n",
    "# f.close()\n",
    "\n",
    "f = open(\"pickle_files/group3_y_sparse.pkl\", 'r')\n",
    "group3_y = pickle.load(f)\n",
    "f.close()\n",
    "\n",
    "f = open(\"pickle_files/group4_y_sparse.pkl\", 'r')\n",
    "group4_y = pickle.load(f)\n",
    "f.close()\n",
    "\n",
    "f = open(\"pickle_files/group5_y_sparse.pkl\", 'r')\n",
    "group5_y = pickle.load(f)\n",
    "f.close()\n",
    "\n",
    "f = open(\"pickle_files/group6_y_sparse.pkl\", 'r')\n",
    "group6_y = pickle.load(f)\n",
    "f.close()\n",
    "\n",
    "f = open(\"pickle_files/group7_y_sparse.pkl\", 'r')\n",
    "group7_y = pickle.load(f)\n",
    "f.close()\n",
    "\n",
    "f = open(\"pickle_files/group8_y_sparse.pkl\", 'r')\n",
    "group8_y = pickle.load(f)\n",
    "f.close()\n",
    "\n",
    "f = open(\"pickle_files/group9_y_sparse.pkl\", 'r')\n",
    "group9_y = pickle.load(f)\n",
    "f.close()\n",
    "\n",
    "f = open(\"pickle_files/group10_y_sparse.pkl\", 'r')\n",
    "group10_y = pickle.load(f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_train_test_validation(data_X, data_Y, train_perc = 0.6, valid_perc = 0.1, test_perc = 0.3):\n",
    "    #Get the total number of rows\n",
    "    nrow = len(data_X)\n",
    "    n_train = int(nrow*train_perc)\n",
    "    n_valid = int(nrow*valid_perc)\n",
    "    n_test  = int(nrow*test_perc)\n",
    "    \n",
    "    #Shuffle the dataset\n",
    "    new_order = np.random.choice(nrow, nrow, replace=False)\n",
    "\n",
    "    #Convert dataset into numpy array for multi-indexing\n",
    "    x_array = np.array(data_X)\n",
    "    y_array = np.array(data_Y)\n",
    "\n",
    "    #The first n_train are the training set\n",
    "    x_train = x_array[new_order[0:n_train]]\n",
    "    y_train = y_array[new_order[0:n_train]]\n",
    "    \n",
    "    #The following n_valid are the validation set\n",
    "    x_valid = x_array[new_order[(n_train):(n_train+n_valid+1)]]\n",
    "    y_valid = y_array[new_order[(n_train):(n_train+n_valid+1)]]\n",
    "    \n",
    "    #The following n_test are the test set\n",
    "    x_test = x_array[new_order[(n_train+n_valid+1):(n_train+n_valid+n_test+2)]]\n",
    "    y_test = y_array[new_order[(n_train+n_valid+1):(n_train+n_valid+n_test+2)]]\n",
    "    \n",
    "    #Return arrays\n",
    "    return x_train, y_train, x_valid, y_valid, x_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split sets for each group\n",
    "\n",
    "# #Group 1\n",
    "# group1_x_train, group1_y_train, group1_x_valid, group1_y_valid, group1_x_test, group1_y_test = split_train_test_validation(group1_x, group1_y)\n",
    "\n",
    "\n",
    "# #Group 2\n",
    "# group2_x_train, group2_y_train, group2_x_valid, group2_y_valid, group2_x_test, group2_y_test = split_train_test_validation(group2_x, group2_y)\n",
    "\n",
    "\n",
    "#Group 3\n",
    "group3_x_train, group3_y_train, group3_x_valid, group3_y_valid, group3_x_test, group3_y_test = split_train_test_validation(group3_x, group3_y)\n",
    "\n",
    "#Group 4\n",
    "group4_x_train, group4_y_train, group4_x_valid, group4_y_valid, group4_x_test, group4_y_test = split_train_test_validation(group4_x, group4_y)\n",
    "\n",
    "\n",
    "#Group 5\n",
    "group5_x_train, group5_y_train, group5_x_valid, group5_y_valid, group5_x_test, group5_y_test = split_train_test_validation(group5_x, group5_y)\n",
    "\n",
    "\n",
    "#Group 6\n",
    "group6_x_train, group6_y_train, group6_x_valid, group6_y_valid, group6_x_test, group6_y_test = split_train_test_validation(group6_x, group6_y)\n",
    "\n",
    "\n",
    "#Group 7\n",
    "group7_x_train, group7_y_train, group7_x_valid, group7_y_valid, group7_x_test, group7_y_test = split_train_test_validation(group7_x, group7_y)\n",
    "\n",
    "\n",
    "#Group 8\n",
    "group8_x_train, group8_y_train, group8_x_valid, group8_y_valid, group8_x_test, group8_y_test = split_train_test_validation(group8_x, group8_y)\n",
    "\n",
    "\n",
    "#Group 9\n",
    "group9_x_train, group9_y_train, group9_x_valid, group9_y_valid, group9_x_test, group9_y_test = split_train_test_validation(group9_x, group9_y)\n",
    "\n",
    "\n",
    "#Group 10\n",
    "group10_x_train, group10_y_train, group10_x_valid, group10_y_valid, group10_x_test, group10_y_test = split_train_test_validation(group10_x, group10_y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chooseGroup_x(number):\n",
    "    if number == 1:\n",
    "        return group1_x_train\n",
    "    elif number == 2:\n",
    "        return group2_x_train\n",
    "    elif number == 3:\n",
    "        return group3_x_train\n",
    "    elif number == 4:\n",
    "        return group4_x_train\n",
    "    elif number == 5:\n",
    "        return group5_x_train\n",
    "    elif number == 6:\n",
    "        return group6_x_train\n",
    "    elif number == 7:\n",
    "        return group7_x_train\n",
    "    elif number == 8:\n",
    "        return group8_x_train\n",
    "    elif number == 9:\n",
    "        return group9_x_train\n",
    "    elif number == 10:\n",
    "        return group10_x_train\n",
    "    \n",
    "def chooseGroup_y(number):\n",
    "    if number == 1:\n",
    "        return group1_y_train\n",
    "    elif number == 2:\n",
    "        return group2_y_train\n",
    "    elif number == 3:\n",
    "        return group3_y_train\n",
    "    elif number == 4:\n",
    "        return group4_y_train\n",
    "    elif number == 5:\n",
    "        return group5_y_train\n",
    "    elif number == 6:\n",
    "        return group6_y_train\n",
    "    elif number == 7:\n",
    "        return group7_y_train\n",
    "    elif number == 8:\n",
    "        return group8_y_train\n",
    "    elif number == 9:\n",
    "        return group9_y_train\n",
    "    elif number == 10:\n",
    "        return group10_y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.4387509798798014,\n",
       " 0.21789913770577476,\n",
       " 0.11178468774496995,\n",
       " 0.08517115233864646,\n",
       " 0.05109746537758035,\n",
       " 0.04060621897047296,\n",
       " 0.03125163313300235,\n",
       " 0.023438724849751763]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create probabilities of each group, so each group is randomly selected proportionally to their number of items\n",
    "total_train = len(group3_x_train) + len(group4_x_train) + len(group5_x_train) + len(group6_x_train) + len(group7_x_train) + len(group8_x_train) + len(group9_x_train) + len(group10_x_train)\n",
    "p = []\n",
    "p.append(len(group3_x_train)/float(total_train))\n",
    "p.append(len(group4_x_train)/float(total_train))\n",
    "p.append(len(group5_x_train)/float(total_train))\n",
    "p.append(len(group6_x_train)/float(total_train))\n",
    "p.append(len(group7_x_train)/float(total_train))\n",
    "p.append(len(group8_x_train)/float(total_train))\n",
    "p.append(len(group9_x_train)/float(total_train))\n",
    "p.append(len(group10_x_train)/float(total_train))\n",
    "\n",
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "numFeatures = group10_x_train[0].shape[1]\n",
    "numOutput = group10_y_train[0].shape[1]\n",
    "\n",
    "def generator(batch_size):\n",
    "    \n",
    "    while True: #Infinite Loop\n",
    "    \n",
    "        #Randomly select a group\n",
    "        groupNumber = np.random.choice(range(3,11), p=p)\n",
    "\n",
    "        #Extract group\n",
    "        group_x = chooseGroup_x(groupNumber)\n",
    "        group_y = chooseGroup_y(groupNumber)\n",
    "\n",
    "        # Create empty arrays to contain batch of features and labels\n",
    "        batch_features = np.empty((batch_size, groupNumber, numFeatures))\n",
    "        batch_labels = np.empty((batch_size, groupNumber, numOutput))\n",
    "        \n",
    "        #Generate random index\n",
    "        batch_indices = np.random.randint(0,len(group_x)-1, size=batch_size)\n",
    "        i = 0\n",
    "        for index in batch_indices:\n",
    "            #np.nan_to_num transforms nan to 0. Without removing nan, the loss function is nan\n",
    "            batch_features[i] = np.nan_to_num(group_x[index].todense())\n",
    "            #batch_features[i] = np.nan_to_num(group[index])          \n",
    "            #Randomly generated output\n",
    "            batch_labels[i] = group_y[index].todense()\n",
    "            i += 1\n",
    "            \n",
    "        yield batch_features, batch_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define Data Parameters\n",
    "batch_size = 128\n",
    "\n",
    "#Model Parameters\n",
    "epochs = 10\n",
    "steps_per_epochs = total_train/batch_size\n",
    "#steps_per_epochs = 1\n",
    "loss_function = \"binary_crossentropy\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential\n",
      "LSTM\n",
      "Dense\n",
      "compile\n",
      "Epoch 1/10\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "print(\"Sequential\")\n",
    "model.add(LSTM(numOutput, input_shape= (None,numFeatures), return_sequences=True, activation='sigmoid', recurrent_activation='sigmoid'))\n",
    "# model.add(LSTM(output_size, input_shape= (None,number_features), return_sequences=True, activation='sigmoid', recurrent_activation='sigmoid'))\n",
    "print(\"LSTM\")\n",
    "model.add(Dense(numOutput, activation = 'sigmoid'))\n",
    "print(\"Dense\")\n",
    "model.compile(loss=loss_function, optimizer='adam', metrics=[categorical_accuracy, binary_accuracy])\n",
    "#model.fit(x, y, epochs=epochs, batch_size=batch_size, verbose=2)\n",
    "print(\"compile\")\n",
    "model.fit_generator(generator=generator(batch_size), steps_per_epoch=steps_per_epochs, epochs=epochs, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def correctInputShape(data_x):\n",
    "    size = data_x.shape[0]\n",
    "    num_features = data_x[0].shape[1]\n",
    "    num_drugs = data_x[0].shape[0]\n",
    "    \n",
    "    x_shaped = np.empty((size, num_drugs, num_features))\n",
    "    \n",
    "    for i in range(size):\n",
    "        x_shaped[i] = np.nan_to_num(data_x[i].todense())\n",
    "    \n",
    "    return x_shaped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def top10prediction(y_true, y_pred):\n",
    "    #put both arrays in the same shape, flatten\n",
    "    pred = y_pred.reshape(-1, y_pred.shape[-1])\n",
    "    true_flat = np.asarray(map(lambda x: np.asarray(x.todense()),y_true))\n",
    "    true = true_flat.reshape(-1, y_true.shape[-1])\n",
    "    \n",
    "    scores = []\n",
    "    \n",
    "    for i in range(len(pred)):\n",
    "        p = pred[i]\n",
    "        t = true[i]\n",
    "        \n",
    "        #Extract top values\n",
    "        top10_pred = set(np.argsort(p)[-10:])\n",
    "        actual_ones = set(np.where(t==1)[0])\n",
    "        \n",
    "        if len(actual_ones)>0:\n",
    "            #Score = #intersection/#actual_ones\n",
    "            score = len(top10_pred.intersection(actual_ones))/float(len(actual_ones))\n",
    "\n",
    "            scores.append(score)\n",
    "    return np.mean(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def allGroupsPredictions(model):\n",
    "#     group1_x_valid_shape = correctInputShape(group1_x_valid)\n",
    "#     group2_x_valid_shape = correctInputShape(group2_x_valid)\n",
    "    group3_x_valid_shape = correctInputShape(group3_x_valid)\n",
    "    group4_x_valid_shape = correctInputShape(group4_x_valid)\n",
    "    group5_x_valid_shape = correctInputShape(group5_x_valid)\n",
    "    group6_x_valid_shape = correctInputShape(group6_x_valid)\n",
    "    group7_x_valid_shape = correctInputShape(group7_x_valid)\n",
    "    group8_x_valid_shape = correctInputShape(group8_x_valid)\n",
    "    group9_x_valid_shape = correctInputShape(group9_x_valid)\n",
    "    group10_x_valid_shape = correctInputShape(group10_x_valid)\n",
    "    \n",
    "    #Predict\n",
    "#     group1_predicted = model.predict(group1_x_valid_shape)\n",
    "#     group2_predicted = model.predict(group2_x_valid_shape)\n",
    "    group3_predicted = model.predict(group3_x_valid_shape)\n",
    "    group4_predicted = model.predict(group4_x_valid_shape)\n",
    "    group5_predicted = model.predict(group5_x_valid_shape)\n",
    "    group6_predicted = model.predict(group6_x_valid_shape)\n",
    "    group7_predicted = model.predict(group7_x_valid_shape)\n",
    "    group8_predicted = model.predict(group8_x_valid_shape)\n",
    "    group9_predicted = model.predict(group9_x_valid_shape)\n",
    "    group10_predicted = model.predict(group10_x_valid_shape)\n",
    "    \n",
    "    \n",
    "    #Measure predictions\n",
    "    group1Pred = top10prediction(group1_y_valid, group1_predicted)\n",
    "    group2Pred = top10prediction(group2_y_valid, group2_predicted)\n",
    "    group3Pred = top10prediction(group3_y_valid, group3_predicted)\n",
    "    group4Pred = top10prediction(group4_y_valid, group4_predicted)\n",
    "    group5Pred = top10prediction(group5_y_valid, group5_predicted)\n",
    "    group6Pred = top10prediction(group6_y_valid, group6_predicted)\n",
    "    group7Pred = top10prediction(group7_y_valid, group7_predicted)\n",
    "    group8Pred = top10prediction(group8_y_valid, group8_predicted)\n",
    "    group9Pred = top10prediction(group9_y_valid, group9_predicted)\n",
    "    group10Pred = top10prediction(group10_y_valid, group10_predicted)\n",
    "    \n",
    "    groupList = [group3Pred, group4Pred, group5Pred, group6Pred, group7Pred, group8Pred,\n",
    "                group9Pred, group10Pred]\n",
    "    \n",
    "    #Average\n",
    "    meanResult = np.mean(groupList)\n",
    "    \n",
    "    return groupList, meanResult"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allGroupsPredictions(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
